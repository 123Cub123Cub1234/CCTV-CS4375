{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\belkh\\Code\\ml_final_project\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Lambda\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.transforms.functional import to_pil_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\belkh\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\jinmang2--ucf_crime\\b97c17ec177f7e377de2b363616b940b64939f4e0766504732b45efc5a69139b (last modified on Mon Apr 22 17:51:43 2024) since it couldn't be found locally at jinmang2/ucf_crime, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "# Directly load with splits if supported\n",
    "datasets = load_dataset(\"jinmang2/ucf_crime\")\n",
    "datasets = datasets['train'].shuffle(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = datasets.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "train_val_split = train_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_val_split['train']\n",
    "val_dataset = train_val_split['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, dataset, target_fps=1, frame_skip=3, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.target_fps = target_fps\n",
    "        self.frame_skip = frame_skip  # Skip every 'frame_skip' frames to reduce temporal resolution\n",
    "        self.transform = transform or transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((64, 64)),  # Resize frames to a smaller dimension\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.feature_extractor = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor.classifier[1] = torch.nn.Identity()  # Removing the final classifier layer\n",
    "        self.feature_extractor.eval()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path = self.dataset[idx]['video_path']\n",
    "        frames = self.load_video(video_path, self.target_fps, self.frame_skip)\n",
    "        features = []\n",
    "        with torch.no_grad():\n",
    "            for frame in frames:\n",
    "                frame = self.transform(frame)\n",
    "                frame = frame.unsqueeze(0)  # Add batch dimension\n",
    "                feature = self.feature_extractor(frame)\n",
    "                features.append(feature.squeeze(0))\n",
    "        features = torch.stack(features)\n",
    "        label = self.dataset[idx]['anomaly']\n",
    "        return features, label\n",
    "\n",
    "    def load_video(self, video_path, target_fps, frame_skip):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        native_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_skip_ratio = max(1, round(native_fps / target_fps)) * frame_skip\n",
    "\n",
    "        frame_idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if frame_idx % frame_skip_ratio == 0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "            frame_idx += 1\n",
    "        cap.release()\n",
    "        return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\belkh\\Code\\ml_final_project\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\belkh\\Code\\ml_final_project\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming 'datasets' is your loaded dataset, e.g., from Hugging Face or another source\n",
    "train_dataset = VideoDataset(train_dataset)\n",
    "val_dataset = VideoDataset(val_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = 1280  # Number of input features\n",
    "        self.hidden_size = 256  # Number of features in hidden state\n",
    "        self.num_layers = 1  # Number of LSTM layers\n",
    "        self.num_classes = 2  # Number of output classes\n",
    "        self.fc = nn.Linear(self.hidden_size, self.num_classes)  # Output layer assumes last hidden state as input\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through LSTM layer\n",
    "        # x of shape (batch, seq, feature)\n",
    "        output, (hn, cn) = self.lstm(x)\n",
    "        # Assuming using the last hidden state\n",
    "        out = self.fc(hn[-1])\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # Assuming outputs are logits and you are doing a classification task\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 100, Loss: 0.7284, Accuracy: 56.00%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, data_loader, val_loader, criterion, optimizer, num_epochs, device, save_path='best_model.pth'):\n",
    "    model = model.to(device)\n",
    "    previous_val_accuracy= float('inf')\n",
    "    best_val_accuracy = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        batch_losses = []\n",
    "        batch_accuracies = []\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                batch_accuracy = 100.0 * total_correct / total_samples\n",
    "                batch_accuracies.append(batch_accuracy)\n",
    "                print(f'Epoch {epoch+1}, Step {i+1}, Loss: {sum(batch_losses) / len(batch_losses):.4f}, '\n",
    "                      f'Accuracy: {batch_accuracy:.2f}%')\n",
    "                total_correct = 0\n",
    "                total_samples = 0\n",
    "                batch_losses = []\n",
    "\n",
    "        # Validation after each epoch\n",
    "        val_accuracy = validate(model, val_loader, criterion, device)\n",
    "        print(f'Epoch {epoch+1}: Validation Loss: {val_accuracy:.4f}')\n",
    "\n",
    "        # Saving the model if it has the best validation loss\n",
    "        if val_accuracy < best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved best model to {save_path}')\n",
    "\n",
    "        # Early stopping condition (less than 10% decrease)\n",
    "        if previous_val_accuracy - val_accuracy < 0.1 * previous_val_accuracy:\n",
    "            print(\"Stopping early due to less than 10% decrease in validation loss.\")\n",
    "            break\n",
    "        previous_val_accuracy = val_accuracy\n",
    "\n",
    "        # Plotting\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(batch_accuracies, label='Accuracy per 100 examples')\n",
    "        plt.title('Accuracy per 100 examples')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Optionally save the final model state\n",
    "    final_model_path = 'final_model.pth'\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f'Saved final model state to {final_model_path}')\n",
    "\n",
    "# Assumptions about other components of your setup\n",
    "model = LSTM()  # Your LSTM model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming 'train_loader' and 'val_loader' are defined (your DataLoader instances)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\belkh\\Code\\ml_final_project\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\belkh\\Code\\ml_final_project\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = VideoDataset(test_dataset)  # Assuming datasets['test'] is your test set\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 1 1\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 1 2\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 1 3\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 1 4\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 2 5\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 3 6\n",
      "tensor([0], device='cuda:0') tensor([7], device='cuda:0') 3 7\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 4 8\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 4 9\n",
      "tensor([3], device='cuda:0') tensor([3], device='cuda:0') 5 10\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 6 11\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 7 12\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 7 13\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 7 14\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 7 15\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 8 16\n",
      "tensor([8], device='cuda:0') tensor([6], device='cuda:0') 8 17\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 9 18\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 10 19\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 11 20\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 11 21\n",
      "tensor([6], device='cuda:0') tensor([0], device='cuda:0') 11 22\n",
      "tensor([6], device='cuda:0') tensor([2], device='cuda:0') 11 23\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 11 24\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 11 25\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 12 26\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 13 27\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 13 28\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 14 29\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 15 30\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 16 31\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 17 32\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 17 33\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 17 34\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 17 35\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 18 36\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 18 37\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 18 38\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 19 39\n",
      "tensor([6], device='cuda:0') tensor([0], device='cuda:0') 19 40\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 19 41\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 19 42\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 20 43\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 21 44\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 22 45\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 22 46\n",
      "tensor([3], device='cuda:0') tensor([13], device='cuda:0') 22 47\n",
      "tensor([12], device='cuda:0') tensor([5], device='cuda:0') 22 48\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 23 49\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 24 50\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 25 51\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 26 52\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 26 53\n",
      "tensor([6], device='cuda:0') tensor([6], device='cuda:0') 27 54\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 27 55\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 27 56\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 28 57\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 29 58\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 30 59\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 31 60\n",
      "tensor([8], device='cuda:0') tensor([8], device='cuda:0') 32 61\n",
      "tensor([3], device='cuda:0') tensor([4], device='cuda:0') 32 62\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 33 63\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 34 64\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 34 65\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 34 66\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 34 67\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 34 68\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 34 69\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 34 70\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 35 71\n",
      "tensor([6], device='cuda:0') tensor([10], device='cuda:0') 35 72\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 35 73\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 35 74\n",
      "tensor([6], device='cuda:0') tensor([5], device='cuda:0') 35 75\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 35 76\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 35 77\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 35 78\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 35 79\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 35 80\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 35 81\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 35 82\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 36 83\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 37 84\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 37 85\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 38 86\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 38 87\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 39 88\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 40 89\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 40 90\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 40 91\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 40 92\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 41 93\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 42 94\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 43 95\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 44 96\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 45 97\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 46 98\n",
      "tensor([12], device='cuda:0') tensor([10], device='cuda:0') 46 99\n",
      "tensor([6], device='cuda:0') tensor([5], device='cuda:0') 46 100\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 47 101\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 48 102\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 48 103\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 48 104\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 49 105\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 50 106\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 50 107\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 50 108\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 51 109\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 52 110\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 52 111\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 52 112\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 53 113\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 54 114\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 55 115\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 56 116\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 57 117\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 57 118\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 57 119\n",
      "tensor([6], device='cuda:0') tensor([4], device='cuda:0') 57 120\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 57 121\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 58 122\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 59 123\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 60 124\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 61 125\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 61 126\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 62 127\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 63 128\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 64 129\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 65 130\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 65 131\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 65 132\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 65 133\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 65 134\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 65 135\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 66 136\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 67 137\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 68 138\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 69 139\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 69 140\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 69 141\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 69 142\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 69 143\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 70 144\n",
      "tensor([8], device='cuda:0') tensor([12], device='cuda:0') 70 145\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 70 146\n",
      "tensor([6], device='cuda:0') tensor([9], device='cuda:0') 70 147\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 70 148\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 71 149\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 72 150\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 73 151\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 73 152\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 73 153\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 74 154\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 75 155\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 76 156\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 77 157\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 78 158\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 79 159\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 80 160\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 80 161\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 80 162\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 80 163\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 81 164\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 82 165\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 83 166\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 84 167\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 85 168\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 85 169\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 86 170\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 86 171\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 87 172\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 88 173\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 89 174\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 90 175\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 91 176\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 91 177\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 91 178\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 92 179\n",
      "tensor([6], device='cuda:0') tensor([13], device='cuda:0') 92 180\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 92 181\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 93 182\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 93 183\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 94 184\n",
      "tensor([12], device='cuda:0') tensor([8], device='cuda:0') 94 185\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 94 186\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 94 187\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 95 188\n",
      "tensor([12], device='cuda:0') tensor([3], device='cuda:0') 95 189\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 96 190\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 97 191\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 98 192\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 98 193\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 98 194\n",
      "tensor([6], device='cuda:0') tensor([6], device='cuda:0') 99 195\n",
      "tensor([0], device='cuda:0') tensor([7], device='cuda:0') 99 196\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 100 197\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 101 198\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 102 199\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 103 200\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 104 201\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 104 202\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 105 203\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 105 204\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 106 205\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 107 206\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 108 207\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 109 208\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 109 209\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 109 210\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 110 211\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 111 212\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 111 213\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 112 214\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 113 215\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 114 216\n",
      "tensor([3], device='cuda:0') tensor([3], device='cuda:0') 115 217\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 115 218\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 116 219\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 116 220\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 116 221\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 116 222\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 117 223\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 117 224\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 117 225\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 118 226\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 119 227\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 120 228\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 121 229\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 122 230\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 122 231\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 122 232\n",
      "tensor([6], device='cuda:0') tensor([8], device='cuda:0') 122 233\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 123 234\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 123 235\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 123 236\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 124 237\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 125 238\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 125 239\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 125 240\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 125 241\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 125 242\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 125 243\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 126 244\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 127 245\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 128 246\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 128 247\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 129 248\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 130 249\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 130 250\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 130 251\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 130 252\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 131 253\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 131 254\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 131 255\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 132 256\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 132 257\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 133 258\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 133 259\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 134 260\n",
      "tensor([6], device='cuda:0') tensor([0], device='cuda:0') 134 261\n",
      "tensor([0], device='cuda:0') tensor([10], device='cuda:0') 134 262\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 135 263\n",
      "tensor([0], device='cuda:0') tensor([7], device='cuda:0') 135 264\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 135 265\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 136 266\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 137 267\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 138 268\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 138 269\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 139 270\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 140 271\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 141 272\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 142 273\n",
      "tensor([4], device='cuda:0') tensor([3], device='cuda:0') 142 274\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 142 275\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 143 276\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 144 277\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 145 278\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 146 279\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 146 280\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 147 281\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 148 282\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 149 283\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 149 284\n",
      "tensor([12], device='cuda:0') tensor([5], device='cuda:0') 149 285\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 150 286\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 151 287\n",
      "tensor([6], device='cuda:0') tensor([4], device='cuda:0') 151 288\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 151 289\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 152 290\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 153 291\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 153 292\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 153 293\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 154 294\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 155 295\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 156 296\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 156 297\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 156 298\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 156 299\n",
      "tensor([12], device='cuda:0') tensor([12], device='cuda:0') 157 300\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 157 301\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 157 302\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 158 303\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 159 304\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 159 305\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 159 306\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 159 307\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 160 308\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 160 309\n",
      "tensor([3], device='cuda:0') tensor([6], device='cuda:0') 160 310\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 160 311\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 160 312\n",
      "tensor([0], device='cuda:0') tensor([13], device='cuda:0') 160 313\n",
      "tensor([0], device='cuda:0') tensor([7], device='cuda:0') 160 314\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 161 315\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 162 316\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 163 317\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 164 318\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 165 319\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 165 320\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 165 321\n",
      "tensor([6], device='cuda:0') tensor([1], device='cuda:0') 165 322\n",
      "tensor([0], device='cuda:0') tensor([4], device='cuda:0') 165 323\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 166 324\n",
      "tensor([6], device='cuda:0') tensor([8], device='cuda:0') 166 325\n",
      "tensor([0], device='cuda:0') tensor([6], device='cuda:0') 166 326\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 167 327\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 168 328\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 169 329\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 170 330\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 170 331\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 170 332\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 170 333\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 170 334\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 171 335\n",
      "tensor([8], device='cuda:0') tensor([0], device='cuda:0') 171 336\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 172 337\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 172 338\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 173 339\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 174 340\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 174 341\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 175 342\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 176 343\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 177 344\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 178 345\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 179 346\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 179 347\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 180 348\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 180 349\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 180 350\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 181 351\n",
      "tensor([6], device='cuda:0') tensor([9], device='cuda:0') 181 352\n",
      "tensor([3], device='cuda:0') tensor([8], device='cuda:0') 181 353\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 181 354\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 182 355\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 182 356\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 183 357\n",
      "tensor([0], device='cuda:0') tensor([12], device='cuda:0') 183 358\n",
      "tensor([0], device='cuda:0') tensor([5], device='cuda:0') 183 359\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 184 360\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 185 361\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 186 362\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 186 363\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 187 364\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 188 365\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 189 366\n",
      "tensor([6], device='cuda:0') tensor([3], device='cuda:0') 189 367\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 189 368\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 190 369\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 190 370\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 191 371\n",
      "tensor([0], device='cuda:0') tensor([9], device='cuda:0') 191 372\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 192 373\n",
      "tensor([0], device='cuda:0') tensor([1], device='cuda:0') 192 374\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 193 375\n",
      "tensor([0], device='cuda:0') tensor([11], device='cuda:0') 193 376\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 194 377\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 195 378\n",
      "tensor([0], device='cuda:0') tensor([2], device='cuda:0') 195 379\n",
      "tensor([5], device='cuda:0') tensor([4], device='cuda:0') 195 380\n",
      "tensor([0], device='cuda:0') tensor([3], device='cuda:0') 195 381\n",
      "tensor([0], device='cuda:0') tensor([8], device='cuda:0') 195 382\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 196 383\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 197 384\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 198 385\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 199 386\n",
      "tensor([3], device='cuda:0') tensor([3], device='cuda:0') 200 387\n",
      "tensor([0], device='cuda:0') tensor([7], device='cuda:0') 200 388\n",
      "tensor([6], device='cuda:0') tensor([3], device='cuda:0') 200 389\n",
      "tensor([0], device='cuda:0') tensor([0], device='cuda:0') 201 390\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_predictions += labels.size(0)\n",
    "                counter += 1\n",
    "                print(predicted, labels, correct_predictions, total_predictions)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m num_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Number of LSTM layers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Number of output classes\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleLSTM\u001b[49m(input_size, hidden_size, num_layers, num_classes)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Loss and optimizer\u001b[39;00m\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer, num_epochs, device):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(data_loader):\n",
    "            print(inputs.shape, labels)\n",
    "            start_time = time.time()  # Start time for processing one batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], Loss: {loss.item():.4f}, Batch Time: {elapsed_time:.2f} sec')\n",
    "\n",
    "# Model configuration\n",
    "input_size = 2048  # Number of input features\n",
    "hidden_size = 256  # Number of features in hidden state\n",
    "num_layers = 1  # Number of LSTM layers\n",
    "num_classes = 2  # Number of output classes\n",
    "\n",
    "model = SimpleLSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Assuming 'train_loader' is defined (your DataLoader instance)\n",
    "train(model, data_loader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.lstm = nn.LSTM(16 * 112 * 112, 128, 2, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: tensor of dimensions (batch_size, sequence_length, C, H, W)\n",
    "        batch_size, seq_length, C, H, W = x.size()\n",
    "        c_in = x.view(batch_size * seq_length, C, H, W)\n",
    "        c_out = self.maxpool(self.relu(self.conv1(c_in)))\n",
    "        r_in = c_out.view(batch_size, seq_length, -1)\n",
    "        r_out, _ = self.lstm(r_in)\n",
    "        r_out = self.fc(r_out[:, -1, :])\n",
    "        return r_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for frames, labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(frames)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Example: Training CRNN\n",
    "model = CRNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, data_loader, criterion, optimizer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
